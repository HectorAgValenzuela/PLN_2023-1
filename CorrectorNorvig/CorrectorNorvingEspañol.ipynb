{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instrucciones"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considera el artículo de Peter Norvig https://norvig.com/spell-correct.html.  En una libreta de Jupyter, replica el artículo considerando lo siguiente:\n",
    "Adapta la función edits1, edits2 para sin considerar la opción de \"transpose\"\n",
    "Programa una tercera función edits3\n",
    "Justifica porqué las funciones edits1, edits2 nos regresan efectivamente las palabras a \"distancia\" 1 y 2 respectivamente de una palabra dada \n",
    "* Adapta todas las funciones edits para el caso del alfabeto en español &check;\n",
    "* Prueba tu corrector con tu propio big.txt (no olvides poner la referencia) &check;\n",
    "* Describe con tus palabras el significado de P(w|c) y P(c|w) ¿porqué es razonable considerar a P(w|c) como el error del modelo?\n",
    "* A qué se refiere Norvig en el punto 4 por \"data on spelling errors\" ¿qué tiene qué ver eso con el error del modelo?\n",
    "* Explica el procedimiento de Norvig para evaluar el modelo\n",
    "* Escribe cuidadosamente tus conclusiones\n",
    "Al igual que antes, el líder del equipo tiene que entregar la libreta corrida y la exportación a html.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código de Norvig\n",
    "Este código define un algoritmo de corrección de ortografía que utiliza la información estadística almacenada en el archivo \"big.txt\" para corregir palabras. Se basa en la idea de que las palabras que se usan con más frecuencia son más probablemente la ortografía correcta de una palabra."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importaciones\n",
    "El código contiene dos importaciones:\n",
    "\n",
    "    \"re\" (de la librería \"regex\" o \"regular expressions\"): esta librería proporciona funciones para trabajar con expresiones regulares en Python. En este código se utiliza la función \"re.findall\" para buscar todas las palabras en un texto.\n",
    "\n",
    "    \"Counter\" de la librería \"collections\": esta librería proporciona una variedad de clases de contenedores para Python, incluido \"Counter\", que es una clase que se utiliza para contar objetos. En este código, se utiliza \"Counter\" para crear una lista de todas las palabras en un archivo de texto y contar la cantidad de veces que cada palabra aparece. La lista de palabras y sus conteos se guardan en la variable \"WORDS\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def words(text)\n",
    "La función \"words\" se utiliza para dividir un texto en una lista de palabras individuales. La función toma una cadena de texto como entrada y utiliza una expresión regular para buscar todas las palabras en el texto.\n",
    "\n",
    "La función \"re.findall\" se utiliza para buscar todas las ocurrencias de una expresión regular (patrón que se buscará) en una cadena de texto y devolverá una lista de ellas. Cada elemento de la lista es una cadena de texto que coincide con el patrón de la expresión regular. La función toma dos argumentos: la expresión regular y la cadena de texto donde se buscarán las ocurrencias. La expresión regular utilizada es r'\\w+'(abreviatura para \"[a-zA-Z0-9_]\"), se utiliza para buscar secuencias de uno o más caracteres alfanuméricos (letras y/o números).\n",
    "\n",
    "Una vez que se han encontrado todas las palabras en el texto, la función convierte todas las letras a minúsculas con el método \"lower()\" y devuelve una lista de las palabras encontradas. Esta lista de palabras es lo que se utiliza en el resto del programa para generar correcciones de ortografía y determinar la probabilidad de una palabra en particular.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words(text): return re.findall(r'[a-zA-ZñÑáéíóúÁÉÍÓÚüÜ]+', text.lower())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WORDS (contador)\n",
    "\"WORDS\" es un objeto de contador que almacena la frecuencia de cada palabra en el archivo big.txt.\n",
    "\n",
    "El contador \"WORDS\" es un objeto de la clase \"Counter\" de la biblioteca \"collections\" de Python. Es una estructura de datos que permite contar la frecuencia de elementos en una lista. En este caso, se utiliza para contar la frecuencia de palabras en el archivo \"big.txt\".\n",
    "\n",
    "Para construir el objeto \"WORDS\", se llama a la función \"words\" para obtener una lista de todas las palabras en el archivo \"big.txt\". Luego, se pasa esta lista a la función \"Counter\" para construir el objeto \"WORDS\". Después de esto, el objeto \"WORDS\" contiene un registro de la frecuencia de cada palabra en el archivo \"big.txt\".\n",
    "\n",
    "El objeto \"WORDS\" se utiliza en la función \"P\" para calcular la probabilidad de una palabra dada. Además, \"WORDS\" se utiliza en la función \"known\" para verificar si una palabra dada se encuentra en el diccionario de palabras almacenado en \"WORDS\"."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como corpus volvimos a tomar el don Quijote. Tomando el feedback que usted nos dio en la tarea pasado ahora si solo tomaremos los caracteres alfabeticos, quitando numeros, comas, giones, etc. Esto lo hacemos con la siguiente expresion regular :\n",
    "\n",
    "[a-zA-ZñÑáéíóúÁÉÍÓÚüÜ]+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORDS = Counter(words(open('../BPE/donQuijote.txt', encoding=\"utf8\").read()))\n",
    "\n",
    "# Si quiere usar el corpus donQuijote.txt obtienes este error : \n",
    "# 'charmap' codec can't decode byte 0x81 in position 20948: character maps to <undefined>\n",
    "# Al poner encoding=\"utf8\" se puede proseguir "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P (probabilidad)\n",
    "La función \"P\" calcula la probabilidad de una palabra dada. Utiliza la frecuencia de la palabra en el archivo big.txt, normalizada por el número total de palabras en el archivo.\n",
    "\n",
    "La función \"P\" se utiliza para calcular la probabilidad de una palabra dada en el archivo \"big.txt\". La probabilidad se calcula como la frecuencia de la palabra en el archivo \"big.txt\" dividida por el número total de palabras en el archivo.\n",
    "\n",
    "La función \"P\" tiene un parámetro obligatorio \"word\" que es la palabra para la cual se quiere calcular la probabilidad. También tiene un parámetro opcional \"N\" que representa el número total de palabras en el archivo \"big.txt\". Si no se proporciona un valor para \"N\", se utiliza el valor predeterminado que es la suma de las frecuencias de todas las palabras en el archivo \"big.txt\".\n",
    "\n",
    "La probabilidad se devuelve como un flotante, que representa la frecuencia de la palabra en el archivo \"big.txt\" en términos de una fracción. Por ejemplo, si la palabra \"hola\" aparece 1000 veces en un archivo de 10,000 palabras, la probabilidad de \"hola\" sería de 0.1 o 10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correction\n",
    "Devuelve la corrección más probable para una palabra dada. Lo hace generando un conjunto de palabras candidatas utilizando la función \"candidates\" y seleccionando la de mayor probabilidad, calculada por \"P\".\n",
    "\n",
    "La función \"correction\" es una función que se utiliza para corregir la ortografía de una palabra. La función toma una palabra como entrada y devuelve la corrección más probable de la ortografía de la palabra.\n",
    "\n",
    "La función \"correction\" hace uso de otras funciones definidas en el código para realizar su tarea. En primer lugar, llama a la función \"candidates\" para generar una lista de posibles correcciones de la ortografía de la palabra. La lista incluye la palabra original y cualquier otra palabra que pueda ser una corrección posible.\n",
    "\n",
    "Luego, la función \"correction\" utiliza la función \"P\" para calcular la probabilidad de cada palabra en la lista de candidatos. Finalmente, la función \"correction\" devuelve la palabra con la probabilidad más alta utilizando la función \"max\" y la función \"P\" como la clave para comparar las palabras.\n",
    "\n",
    "En resumen, la función \"correction\" es una función que utiliza un modelo de lenguaje basado en la frecuencia de palabras para corregir la ortografía de una palabra dada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candidates\n",
    "Genera un conjunto de palabras candidatas para una palabra dada llamando a \"known\", \"edits1\" y \"edits2\". \n",
    "\n",
    "La función \"candidates\" es una función que se utiliza para generar una lista de posibles correcciones de la ortografía de una palabra dada. La función toma una palabra como entrada y devuelve una lista de palabras que pueden ser posibles correcciones de la ortografía.\n",
    "\n",
    "La función \"candidates\" hace uso de otras funciones definidas en el código para generar la lista de candidatos. En primer lugar, la función llama a la función \"known\" con la palabra original como entrada. La función \"known\" verifica si la palabra original se encuentra en el diccionario de palabras y, si es así, la agrega a la lista de candidatos.\n",
    "\n",
    "Si la palabra original no se encuentra en el diccionario, la función \"candidates\" llama a la función \"edits1\" con la palabra original como entrada. La función \"edits1\" genera una lista de todas las ediciones que están a una edición de distancia de la palabra original. Luego, la función \"known\" se llama con esta lista de ediciones y agrega todas las palabras que se encuentran en el diccionario a la lista de candidatos.\n",
    "\n",
    "Si aún no se han encontrado palabras en el diccionario después de las ediciones de una distancia, la función \"candidates\" llama a la función \"edits2\" con la palabra original como entrada. La función \"edits2\" genera una lista de todas las ediciones que están a dos ediciones de distancia de la palabra original. Luego, la función \"known\" se llama con esta lista de ediciones y agrega todas las palabras que se encuentran en el diccionario a la lista de candidatos.\n",
    "\n",
    "Si después de todas estas ediciones aún no se han encontrado palabras en el diccionario, la función \"candidates\" devuelve la palabra original como única entrada en la lista de candidatos.\n",
    "\n",
    "En resumen, la función \"candidates\" es una función que utiliza un modelo de lenguaje basado en la frecuencia de palabras para generar una lista de posibles correcciones de la ortografía de una palabra dada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or known(edits3(word)) or [word])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Known\n",
    "\"Known\" devuelve el subconjunto de palabras de una lista dada que aparecen en el diccionario de palabras almacenado en \"WORDS\". \n",
    "\n",
    "La función \"known\" se utiliza para buscar palabras conocidas en el diccionario de WORDS. Esta función toma una lista de palabras como argumento y devuelve un conjunto con aquellas palabras que aparecen en el diccionario de WORDS. La búsqueda se realiza usando una comprensión de listas, que es una forma concisa y eficiente de generar una nueva lista a partir de una secuencia existente.\n",
    "\n",
    "En la comprensión de listas, se itera sobre la secuencia y se seleccionan aquellos elementos que cumplen una determinada condición. En este caso, se itera sobre la lista de palabras y se seleccionan aquellas que están presentes en el diccionario de WORDS. Finalmente, se convierte el resultado en un conjunto para eliminar duplicados y se devuelve el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### edits1\n",
    "\"Edits1\" genera un conjunto de palabras que están a una edición de distancia de la palabra original.\n",
    "\n",
    "La función \"edits1\" se utiliza para generar todas las correcciones posibles para una palabra que se encuentra a una distancia de edición de una sola operación. Esta función toma una palabra como argumento y devuelve un conjunto con todas las posibles correcciones.\n",
    "\n",
    "La función primero genera todas las divisiones posibles de la palabra en dos partes, la izquierda (L) y la derecha (R), utilizando una comprensión de listas. Luego, se realizan cuatro operaciones diferentes para generar las correcciones:\n",
    "\n",
    "    Borrado: Se crean nuevas palabras eliminando la primera letra de R.\n",
    "    Transposición: Se crean nuevas palabras intercambiando las posiciones de las dos primeras letras de R.\n",
    "    Reemplazo: Se crean nuevas palabras reemplazando cada letra de R con una letra diferente del alfabeto.\n",
    "    Inserción: Se crean nuevas palabras insertando una letra diferente del alfabeto en cada posición de R.\n",
    "\n",
    "Todas las correcciones generadas se agrupan en un conjunto para eliminar duplicados y se devuelve el resultado.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'aábcdeéfghiíjklmnñoópqrstuúvwxyz'\n",
    "    splits     = [(word[:i+1], word[i+1:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + replaces + inserts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### edits 2\n",
    "\"edits2\" genera un conjunto de palabras que están a dos ediciones de distancia. Las ediciones incluyen la eliminación, la transposición, la sustitución y la inserción de caracteres.\n",
    "\n",
    "La función \"edits2\" se utiliza para generar todas las correcciones posibles para una palabra que se encuentran a una distancia de edición de dos operaciones. Esta función utiliza la función \"edits1\" para generar las correcciones a una distancia de edición de una sola operación, y luego aplica la función \"edits1\" a cada una de estas correcciones.\n",
    "\n",
    "En otras palabras, la función \"edits2\" toma cada palabra que se encuentra a una distancia de edición de una sola operación y genera todas las correcciones posibles a una distancia de edición de dos operaciones a partir de esa palabra. Finalmente, se agrupan todas las correcciones en una lista y se devuelve el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## Distancia de edits1 y edits2 -->\n",
    "En clase se vio el siguiente algoritmo\n",
    "\n",
    "Regla inicial :\n",
    "\n",
    "$D[i,0] = i$\n",
    "\n",
    "$D[0,j] = j$\n",
    "\n",
    "Regla inductiva :\n",
    "\n",
    "$D[i,j] = min{D[i-1,j] + 1, D[i,j-1] + 1, D[i-1,j-1] + \\lambda}$\n",
    "\n",
    "$\\lambda = \n",
    "    \\left\\lbrace\\begin{array}{c} \n",
    "        2 \\hspace{0.5cm} \\text{si} \\hspace{0.5cm} \\text{source}[i] \\neq \\text{target}[j]  \\\\\n",
    "        0 \\hspace{0.5cm} \\text{si} \\hspace{0.5cm} \\text{source}[i] = \\text{target}[j]\n",
    "    \\end{array}\\right.\n",
    "$\n",
    "\n",
    "Donde obtenemos la distancia minima para pasar de una palabra a otra. De aqui en adelante cuando digamos distancia nos referiremos a la distancia segun este algoritmo. En la siguiente celda esta el algoritmo programado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(s, t):\n",
    "    \"\"\"\n",
    "    Calcula la distancia (de Levenshtein) entre dos cadenas de caracteres con el algoritmo visto en clase.\n",
    "    \"\"\"\n",
    "    m, n = len(s), len(t) # Obtenemos la longitud de las palabras\n",
    "    # Creamos un arreglo de 0's de (m+1)*(n+1), donde se guardaran las subdistancias\n",
    "    d = [[0] * (n + 1) for i in range(m + 1)] \n",
    "\n",
    "    # Aplicamos el metodo de distancias de levenshtein\n",
    "    for i in range(1, m + 1):\n",
    "        d[i][0] = i\n",
    "\n",
    "    for j in range(1, n + 1):\n",
    "        d[0][j] = j\n",
    "\n",
    "    for j in range(1, n + 1):\n",
    "\n",
    "        for i in range(1, m + 1):\n",
    "\n",
    "            d[i][j] = min(d[i - 1][j] + 1, d[i][j - 1] + 1, d[i - 1][j - 1] + 2*(not s[i - 1] == t[j - 1]))\n",
    "                \n",
    "    return d[m][n]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si comparamos este algoritmo con las funciones edits del articulo, vemos que edits1 no da palabras a 1 de distancia, de igual manera con edits2 no da palabras a 2 de distancia segun nuestro algoritmo. En general edits1 te da palabras a 0,1 y 2 de distancia, edits2 te da palabras a 0,1,2,3 y 4 de distancia.\n",
    "\n",
    "Podriamos editar edits1 de manera facil para obtener solo palabras a 1 de distancia, eliminando la operacion replaces, como se ve en el siguiente codigo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edits1dis(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'aábcdeéfghiíjklmnñoópqrstuúüvwxyz'\n",
    "    splits     = [(word[:i+1], word[i+1:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + inserts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto lo puedes comprobar con la siguiente celda. Si la ejecutas con el bloque que utiliza edits1, veras como te regresara palabras a 2 y a 0 de distancia, a diferencia del edits1dis del cual no obtendras ningun output porque todos estan a 1 de distancia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edits1\n",
      "0\n",
      "madderaa\n"
     ]
    }
   ],
   "source": [
    "palabra = 'madderaa'\n",
    "edit1 = list(edits1(palabra))\n",
    "edit1dis = list(edits1dis(palabra))\n",
    "\n",
    "\n",
    "for i in range(len(edit1)):\n",
    "    if (distance(palabra,edit1[i]) == 0):\n",
    "        print(\"edits1\")\n",
    "        print(distance(palabra,edit1[i]))\n",
    "        print(edit1[i])\n",
    "\n",
    "# for i in range(len(edit1dis)):\n",
    "#     if (distance(palabra,edit1dis[i]) != 1):\n",
    "#         print(\"edits1dis\")\n",
    "#         print(distance(palabra,edit1dis[i]))\n",
    "#         print(edit1dis[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para edits2 no es tan facil como solo llamar edits1dis en lugar de edits1, si hacemos esto \\\"edits2dis\\\" nos arrojara palabras a distancia 2 o menores. Por lo tanto debemos hacer un analisis mas a profundidad para encontrar el edits2 adecuado."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### edits 3\n",
    "\"edits3\" genera un conjunto de palabras que están a tes ediciones de distancia. Las ediciones incluyen la eliminación, la transposición, la sustitución y la inserción de caracteres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edits3(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e3 for e1 in edits1(word) for e3 in edits2(e1))\n",
    "\n",
    "# # Esto es lo mismo    \n",
    "# def edits3(word):\n",
    "#     \"All edits that are three edits away from `word`.\"\n",
    "#     e3 = []\n",
    "#     for e1 in edits1(word):\n",
    "#         for e2 in edits2(e1):\n",
    "#             e3.append(e2)\n",
    "#     return e3\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  P(w|c) y P(c|w)\n",
    "\n",
    "Donde c es la palabra candidata como correccion (palabra del diccionario) y w la palabra a corregir (palabra dada por el usuario).\n",
    "\n",
    "P(c|w) es la probabilidad que tiene una palabra candidata del diccionario \"c\" a ser la palabra que quizo escribir el usuario, siendo que escribió la palabra \"w\".\n",
    "\n",
    "P(w|c) es la probabilidad de que el usuario escriba \"w\", cuando realmente quiso escribir la palabra del diccionario \"c\".\n",
    "\n",
    "Ahora, ¿porque es razonable considerar a P(w|c) como el error del modelo?\n",
    "\n",
    "Cuando la palabra dada por el usuario es muy parecida a una en el diccionario P(w|c) toma un valor cercano a 1, en contraparte cuando la palabra del usuario no se parece a ninguna del diccionario P(w|c) da un valor cercano a 0, por lo tanto un buen modelo deberia de dar siempre valores de P(w|c) cercanos a 1, de lo contrario significaria que necesitamos actualizar nuestro diccionario, ya que los usuario estan usando palabras que no se contemplan o nuestro algoritmo de edicion de palabras es inefectivo. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data on spelling errors\n",
    "\n",
    "Se refiere a corpus que contienen escritos electronicos que las personas hacen en su vida cotidiana, como e-mail, sms, entradas de blogs, etc. Los cuales a diferencia de los escritos profecionales cuentan con errores \\\" normales \\\" que la mayoria de las personas hace al momento de escribir.\n",
    "\n",
    "Entonces, ¿que tiene que ver eso con el error del modelo?\n",
    "\n",
    "Al saber esto podemos tener un mejor valor de P(w|c), ya que tendriamos las formas en las que se equivocan las personas (w) al intentar escribir una cierta palabra (c)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos nuestro corrector necesitamos una forma de saber qué tan bien lo está haciendo, para esto, Norving hace un conjunto de prubas unitarias. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unit_tests()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero crea un función que se encarga de hacer pruebas para cada caso de corrección. Esto es:\n",
    "* Para una inserción (una letra faltante)\n",
    "* Para dos reemplazos (corregir dos letras de la palabra)\n",
    "* Para un solo reemplazo\n",
    "* Para dos inserciones\n",
    "* Para un eliminar\n",
    "* Para un transponer (Cambiar de lugar dos letras)\n",
    "* Para un transponer y un eliminar\n",
    "* Para una palabra conocida\n",
    "* Para una palabra desconocida\n",
    "\n",
    "Además, hace pruebas de split, conteo de palabras en el corpus y pruebas de probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_tests():\n",
    "    # Pruebas unitarias con las operaciones\n",
    "    assert correction('cabalo') == 'caballo'            # insert\n",
    "    assert correction('corractd') == 'correcto'         # replace 2\n",
    "    assert correction('trimpeta') == 'trompeta'         # replace\n",
    "    assert correction('inconvenien') == 'inconveniente' # insert 2\n",
    "    assert correction('arreeo') == 'arreo'              # delete\n",
    "    assert correction('srevir') =='servir'              # transpose\n",
    "    assert correction('sreviir') =='servir'             # transpose + delete\n",
    "    assert correction('palabra') == 'palabra'           # known\n",
    "    assert correction('quíntuple') == 'quíntuple'       # unknown\n",
    "    \n",
    "    # Prueba haciendo un split de la palabra\n",
    "    assert words('Esto es una prueba.') == ['esto', 'es', 'una', 'prueba']\n",
    "    \n",
    "    # Prueba con las frecuencias\n",
    "    assert Counter(words('Esto es una prueba. 123; Una PRUEBA es esto.')) == (\n",
    "           Counter({'esto': 2, 'es': 2, 'una': 2, 'prueba': 2, '123': 1}))\n",
    "    \n",
    "    # Prueba con el tamanño del set de palabras distintas\n",
    "    assert len(WORDS) == 22942\n",
    "\n",
    "    # Prueba con el tamaño del ser con palabras distintas\n",
    "    assert sum(WORDS.values()) == 381226\n",
    "\n",
    "    # Prueba con las 10 palabras más comunes\n",
    "    assert WORDS.most_common(10) == [\n",
    "       ('que', 20628),\n",
    "       ('de', 18214),\n",
    "       ('y', 18189),\n",
    "       ('la', 10363),\n",
    "       ('a', 9824),\n",
    "       ('en', 8242),\n",
    "       ('el', 8210),\n",
    "       ('no', 6335),\n",
    "       ('los', 4748),\n",
    "       ('se', 4691)]\n",
    "\n",
    "     # Prueba con la frecuencia de una palabra, en este caso \"que\"\n",
    "    assert WORDS['que'] == 20628\n",
    "    assert P('quíntuple') == 0\n",
    "    assert 0.05 < P('que') < 0.06\n",
    "    return 'unit_tests pass'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spelltest(tests, verbose=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función recibe una lista de pares (right, wrong) e itera sobre cada par. Llama a la función \"correction\" con la palabra incorrecta y verifica si el resultado coincide con la palabra correcta.\n",
    "\n",
    "La función realiza un seguimiento del número de palabras correctamente corregidas en la variable \"good\" y el número de palabras desconocidas en la variable \"unknown\". Si el argumento \"verbose\" es Verdadero, la función imprime información sobre las correcciones que fueron incorrectas.\n",
    "\n",
    "Finalmente, la función calcula el porcentaje de correcciones correctas y el porcentaje de palabras desconocidas, e imprime esta información junto con la velocidad de procesamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spelltest(tests, verbose=False):\n",
    "    \"Run correction(wrong) on all (right, wrong) pairs; report results.\"\n",
    "    import time\n",
    "    start = time.clock()\n",
    "    good, unknown = 0, 0\n",
    "    n = len(tests)\n",
    "    for right, wrong in tests:\n",
    "        w = correction(wrong)\n",
    "        good += (w == right)\n",
    "        if w != right:\n",
    "            unknown += (right not in WORDS)\n",
    "            if verbose:\n",
    "                print('correction({}) => {} ({}); expected {} ({})'\n",
    "                      .format(wrong, w, WORDS[w], right, WORDS[right]))\n",
    "    dt = time.clock() - start\n",
    "    print('{:.0%} of {} correct ({:.0%} unknown) at {:.0f} words per second '\n",
    "          .format(good / n, n, unknown / n, n / dt))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testset(lines)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función Testset toma una lista de cadenas llamadas líneas, donde cada cadena tiene el formato \"correcto: wrong1 wrong2\" (es decir, una respuesta correcta seguida de dos puntos y luego una lista de respuestas incorrectas separadas por espacios).\n",
    "\n",
    "Luego, la función usa una lista de comprensión para dividir cada cadena en una tupla de (right, wrong) dividiendo en el carácter :. Para cada una de estas tuplas, la función luego divide la cadena de errores (que es una lista de respuestas incorrectas separadas por espacios) en una lista de respuestas incorrectas individuales y crea una nueva tupla de (right, wrong) para cada combinación de correcto e incorrecto.\n",
    "\n",
    "Finalmente, la función devuelve una lista de estas tuplas (right, wrong)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Testset(lines):\n",
    "    \"Parse 'right: wrong1 wrong2' lines into [('right', 'wrong1'), ('right', 'wrong2')] pairs.\"\n",
    "    return [(right, wrong)\n",
    "            for (right, wrongs) in (line.split(':') for line in lines)\n",
    "            for wrong in wrongs.split()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cubrir una amplia gama de palabras, es importante contar con un diccionario que tenga un tamaño considerable. Además, es importante actualizarlo con regularidad para incorporar correcciones y nuevos términos. De esta manera, podremos asegurarnos de que nuestro diccionario sea lo más completo y preciso posible."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ca4ae65869d2cb0a1ce9a252154e55d284ddfed7dca74e9ec9cf70dfaaed74d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
