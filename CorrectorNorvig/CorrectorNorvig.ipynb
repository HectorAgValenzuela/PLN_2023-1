{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instrucciones"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considera el artículo de Peter Norvig https://norvig.com/spell-correct.html.  En una libreta de Jupyter, replica el artículo considerando lo siguiente:\n",
    "Adapta la función edits1, edits2 para sin considerar la opción de \"transpose\"\n",
    "Programa una tercera función edits3\n",
    "Justifica porqué las funciones edits1, edits2 nos regresan efectivamente las palabras a \"distancia\" 1 y 2 respectivamente de una palabra dada \n",
    "* Adapta todas las funciones edits para el caso del alfabeto en español\n",
    "* Prueba tu corrector con tu propio big.txt (no olvides poner la referencia)\n",
    "* Describe con tus palabras el significado de P(w|c) y P(c|w) ¿porqué es razonable considerar a P(w|c) como el error del modelo\n",
    "* A qué se refiere Norvig en el punto 4 por \"data on spelling errors\" ¿qué tiene qué ver eso con el error del modelo?\n",
    "* Explica el procedimiento de Norvig para evaluar el modelo\n",
    "* Escribe cuidadosamente tus conclusiones\n",
    "Al igual que antes, el líder del equipo tiene que entregar la libreta corrida y la exportación a html.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código de Norvig\n",
    "Este código define un algoritmo de corrección de ortografía que utiliza la información estadística almacenada en el archivo \"big.txt\" para corregir palabras. Se basa en la idea de que las palabras que se usan con más frecuencia son más probablemente la ortografía correcta de una palabra."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicación:\n",
    "Este código define un algoritmo de corrección de ortografía que utiliza la información estadística almacenada en el archivo \"big.txt\" para corregir palabras. Se basa en la idea de que las palabras que se usan con más frecuencia son más probablemente la ortografía correcta de una palabra.\n",
    "\n",
    "La función \"words\" utiliza expresiones regulares para encontrar todas las secuencias de caracteres de palabras (letras, dígitos y subrayados) en un texto dado y convertirlos a minúsculas. \"WORDS\" es un objeto de contador que almacena la frecuencia de cada palabra en el archivo big.txt.\n",
    "\n",
    "La función \"P\" calcula la probabilidad de una palabra dada. Utiliza la frecuencia de la palabra en el archivo big.txt, normalizada por el número total de palabras en el archivo.\n",
    "\n",
    "La función \"correction\" devuelve la corrección más probable para una palabra dada. Lo hace generando un conjunto de palabras candidatas utilizando la función \"candidates\" y seleccionando la de mayor probabilidad, calculada por \"P\".\n",
    "\n",
    "La función \"candidates\" genera un conjunto de palabras candidatas para una palabra dada llamando a \"known\", \"edits1\" y \"edits2\". \"Known\" devuelve el subconjunto de palabras de una lista dada que aparecen en el diccionario de palabras almacenado en \"WORDS\". \"Edits1\" genera un conjunto de palabras que están a una edición de distancia de la palabra original, y \"edits2\" genera un conjunto de palabras que están a dos ediciones de distancia. Las ediciones incluyen la eliminación, la transposición, la sustitución y la inserción de caracteres."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def words(text)\n",
    "This is a function definition in the Python programming language. It takes in a single argument text and returns a list of words contained in the argument.\n",
    "\n",
    "The function uses a regular expression re.findall(r'\\w+', text.lower()) to find all the words in the input text after converting it to lowercase. The regular expression \\w+ matches one or more word characters (letters, digits, or underscores), effectively matching all the words in the input text.\n",
    "\n",
    "The re module is the Python module for working with regular expressions. The re.findall function is used to find all non-overlapping occurrences of the regular expression pattern in the input string and return them as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words(text): return re.findall(r'\\w+', text.lower())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WORDS (contador)\n",
    "\"WORDS\" es un objeto de contador que almacena la frecuencia de cada palabra en el archivo big.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORDS = Counter(words(open('big.txt').read()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P (probabilidad)\n",
    "La función \"P\" calcula la probabilidad de una palabra dada. Utiliza la frecuencia de la palabra en el archivo big.txt, normalizada por el número total de palabras en el archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correction\n",
    "Devuelve la corrección más probable para una palabra dada. Lo hace generando un conjunto de palabras candidatas utilizando la función \"candidates\" y seleccionando la de mayor probabilidad, calculada por \"P\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candidates\n",
    "Genera un conjunto de palabras candidatas para una palabra dada llamando a \"known\", \"edits1\" y \"edits2\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Known\n",
    "\"Known\" devuelve el subconjunto de palabras de una lista dada que aparecen en el diccionario de palabras almacenado en \"WORDS\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### edits1\n",
    "\"Edits1\" genera un conjunto de palabras que están a una edición de distancia de la palabra original\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### edits 2\n",
    "\"edits2\" genera un conjunto de palabras que están a dos ediciones de distancia. Las ediciones incluyen la eliminación, la transposición, la sustitución y la inserción de caracteres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ca4ae65869d2cb0a1ce9a252154e55d284ddfed7dca74e9ec9cf70dfaaed74d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
