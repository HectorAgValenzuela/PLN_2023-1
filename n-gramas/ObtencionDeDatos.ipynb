{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creditos\n",
    "\n",
    "Los datos de la manianera los obtuvimos del grupo @nostrodata\n",
    "* GitHub : https://github.com/NOSTRODATA/conferencias_matutinas_amlo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libreta 1: Obención de datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importaciones\n",
    "* Importamos la librería pandas para manipular fácimodel1ente los archivos <code>.csv</code>.\n",
    "* Importamos la librería glob para leer fácimodel1ente los archivos <code>.csv</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para libretas 1 y 2\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import random as rd\n",
    "\n",
    "# Para libretas 3\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.lm import MLE\n",
    "from nltk.lm import Laplace\n",
    "from nltk.lm import  KneserNeyInterpolated"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza de los datos\n",
    "En la siguiente linea de código se usa la función <code>glob</code> para generalizar las carpetas del dataset para extraer todos los <code>.csv</code> de el mes de enero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = glob.glob('conferenciasMatutinasAmlo/2022/1-2022/enero */mananera_*_01_2022.csv')\n",
    "# print(csv_files)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos las rutas, iteramos sobre ellas y guardamos todos los datos en una lista llamada <code>filelist</code>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = []\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    filelist.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numero de manianeras de enero 2022\n",
    "len(filelist)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos uno de los dataframes de la lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participante</th>\n",
       "      <th>Texto</th>\n",
       "      <th>Sentimiento</th>\n",
       "      <th>Palabras</th>\n",
       "      <th>Dia</th>\n",
       "      <th>Mes</th>\n",
       "      <th>Anio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRESIDENTE ANDRES MANUEL LOPEZ OBRADOR</td>\n",
       "      <td>Buenos días.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRESIDENTE ANDRES MANUEL LOPEZ OBRADOR</td>\n",
       "      <td>Pues vamos a informar, como todos los martes, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JORGE ALCOCER VARELA</td>\n",
       "      <td>Con su permiso, señor presidente.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JORGE ALCOCER VARELA</td>\n",
       "      <td>Muy buenos días a todas y a todos ustedes.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JORGE ALCOCER VARELA</td>\n",
       "      <td>Como señala el señor presidente, en este momen...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>PRESIDENTE ANDRES MANUEL LOPEZ OBRADOR</td>\n",
       "      <td>Todo esto lo comento porque sí hay toda una ca...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>PRESIDENTE ANDRES MANUEL LOPEZ OBRADOR</td>\n",
       "      <td>Nada más porque por respeto no hablo de que en...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>PREGUNTA</td>\n",
       "      <td>¿Contra Del Mazo?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>PRESIDENTE ANDRES MANUEL LOPEZ OBRADOR</td>\n",
       "      <td>Y contra otras candidatas, que me enteré que ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>PRESIDENTE ANDRES MANUEL LOPEZ OBRADOR</td>\n",
       "      <td>Bueno, nos vemos mañana.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>358 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Participante  \\\n",
       "0    PRESIDENTE ANDRES MANUEL LOPEZ OBRADOR   \n",
       "1    PRESIDENTE ANDRES MANUEL LOPEZ OBRADOR   \n",
       "2                      JORGE ALCOCER VARELA   \n",
       "3                      JORGE ALCOCER VARELA   \n",
       "4                      JORGE ALCOCER VARELA   \n",
       "..                                      ...   \n",
       "353  PRESIDENTE ANDRES MANUEL LOPEZ OBRADOR   \n",
       "354  PRESIDENTE ANDRES MANUEL LOPEZ OBRADOR   \n",
       "355                                PREGUNTA   \n",
       "356  PRESIDENTE ANDRES MANUEL LOPEZ OBRADOR   \n",
       "357  PRESIDENTE ANDRES MANUEL LOPEZ OBRADOR   \n",
       "\n",
       "                                                 Texto  Sentimiento  Palabras  \\\n",
       "0                                         Buenos días.          0.0         2   \n",
       "1    Pues vamos a informar, como todos los martes, ...          0.0        52   \n",
       "2                    Con su permiso, señor presidente.          0.0         5   \n",
       "3           Muy buenos días a todas y a todos ustedes.          0.0         9   \n",
       "4    Como señala el señor presidente, en este momen...          0.0        55   \n",
       "..                                                 ...          ...       ...   \n",
       "353  Todo esto lo comento porque sí hay toda una ca...          0.0        46   \n",
       "354  Nada más porque por respeto no hablo de que en...          0.0        41   \n",
       "355                                  ¿Contra Del Mazo?          0.0         3   \n",
       "356   Y contra otras candidatas, que me enteré que ...          0.0        49   \n",
       "357                           Bueno, nos vemos mañana.          0.0         4   \n",
       "\n",
       "     Dia  Mes  Anio  \n",
       "0     18    1  2022  \n",
       "1     18    1  2022  \n",
       "2     18    1  2022  \n",
       "3     18    1  2022  \n",
       "4     18    1  2022  \n",
       "..   ...  ...   ...  \n",
       "353   18    1  2022  \n",
       "354   18    1  2022  \n",
       "355   18    1  2022  \n",
       "356   18    1  2022  \n",
       "357   18    1  2022  \n",
       "\n",
       "[358 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filelist[2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora limpiamos columas que no nos sirven mediante la función <code>drop()</code> de pandas\n",
    "\n",
    "Después filtramos los participantes para sólo tener diálogos del presidente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredDf = []\n",
    "for df in filelist:\n",
    "    # Eliminamos columnas\n",
    "    df = df.drop(['Sentimiento', 'Palabras', 'Dia', 'Mes', 'Anio'], axis=1)\n",
    "\n",
    "    # Filtramos para sólo tener participaciones del presidente\n",
    "    df = df[df['Participante'] == 'PRESIDENTE ANDRES MANUEL LOPEZ OBRADOR']\n",
    "\n",
    "    df = df.drop(['Participante'], axis=1)\n",
    "\n",
    "    # left_aligned_df = df.style.set_properties(**{'text-align': 'left'})\n",
    "    \n",
    "    # filteredDf.append(left_aligned_df)\n",
    "    filteredDf.append(df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos uno de los dataframes para confirmar que las columnas se eliminaron y sólo hay participaciones del presidente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Buenos días.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vamos a iniciar la semana con el quién es quié...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Vamos a los videos.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Muy bien. Pues vamos adelante. Quedó pendient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Pues muy bien, hay que esperar a que resuelva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>Bueno, vamos a desayunar.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>Con Beatriz.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>Al rato, al rato.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>Ah, pero ya tenemos el informe, te lo van a e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>Bueno, nos vemos.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Texto\n",
       "0                                         Buenos días.\n",
       "1    Vamos a iniciar la semana con el quién es quié...\n",
       "44                                 Vamos a los videos.\n",
       "98    Muy bien. Pues vamos adelante. Quedó pendient...\n",
       "103   Pues muy bien, hay que esperar a que resuelva...\n",
       "..                                                 ...\n",
       "309                          Bueno, vamos a desayunar.\n",
       "311                                       Con Beatriz.\n",
       "313                                  Al rato, al rato.\n",
       "315   Ah, pero ya tenemos el informe, te lo van a e...\n",
       "316                                  Bueno, nos vemos.\n",
       "\n",
       "[140 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filteredDf[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archivo de texto"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos todos los datos filtrados, los guardaremos en un archivo, alineandolos a la izquierda y que cada oración dicha por AMLO esté en una línea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"conferencias_matutinas_amlo.txt\", \"w\", encoding='utf-8') as f:\n",
    "\n",
    "    \n",
    "#     for i, df in enumerate(filteredDf):\n",
    "\n",
    "#         # Cambiamos la indexacion para que este corrida\n",
    "#         inx = range(0,df.shape[0])\n",
    "#         dfIndex = df.reindex(index=inx) \n",
    "\n",
    "#         for j in range(df.shape[0]) :\n",
    "\n",
    "#             texto_str = str(dfIndex['Texto'][j]).strip()\n",
    "\n",
    "#             if texto_str == 'nan' :\n",
    "#                 continue\n",
    "\n",
    "#             f.write(texto_str + '\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corpus donde cada linea es una oracion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"conferencias_matutinas_amlo.txt\", \"w\", encoding='utf-8') as f:\n",
    "\n",
    "    sentence = str()\n",
    "\n",
    "    for df in filteredDf:\n",
    "\n",
    "        for i in range(len(df)) :\n",
    "\n",
    "            text_str = df['Texto'].iloc[i]\n",
    "\n",
    "            for word in text_str :\n",
    "                \n",
    "                if word == '.' :\n",
    "\n",
    "                    sentence += word\n",
    "                    f.write(sentence.strip() + '\\n')\n",
    "                    sentence = str()\n",
    "\n",
    "                else :\n",
    "\n",
    "                    sentence += word    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libreta 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partimos el corpus en entrenamiento y prueba de forma aleatoria"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero contaremos el numero de oraciones (lineas) que tiene nuestro corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('conferencias_matutinas_amlo.txt', 'r', encoding='utf-8') as f :\n",
    "\n",
    "    lineCount = 0\n",
    "\n",
    "    for line in f :\n",
    "\n",
    "        lineCount += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos el numero de lineas que tendra el archivo de pruebas y un arreglo con las lineas que iran en dicho archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd.seed(16) # Semilla \n",
    "porcentage = 20\n",
    "testPart = int(lineCount*porcentage/100)\n",
    "\n",
    "\n",
    "testLines = []\n",
    "while len(testLines) != testPart :\n",
    "\n",
    "    random = rd.randint(0,lineCount-1)\n",
    "    \n",
    "    if random not in testLines : # Si el numero random no esta ya en la lista testLines entonces agregalo\n",
    "\n",
    "        testLines.append(random)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora crearemos dos nuevos archivos, el de entrenamiento y el de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"conferencias_matutinas_amlo.txt\", \"r\", encoding='utf-8') as f :\n",
    "\n",
    "    with open(\"train.txt\", \"w\", encoding='utf-8') as train :\n",
    "\n",
    "        with open(\"test.txt\", \"w\", encoding='utf-8') as test :\n",
    "\n",
    "            for i, line in enumerate(f) :\n",
    "\n",
    "                if i in testLines : # Si la linea i esta en testLines escribelo en el arhivo test\n",
    "\n",
    "                    test.write(line)\n",
    "\n",
    "                else : # De lo contrario va en train\n",
    "                    train.write(line)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos si se hizo bien la separacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3909\n",
      "3128\n",
      "781\n",
      "3909\n"
     ]
    }
   ],
   "source": [
    "with open('train.txt', 'r', encoding='utf-8') as f :\n",
    "\n",
    "    lineCountTrain = 0\n",
    "\n",
    "    for line in f :\n",
    "\n",
    "        lineCountTrain += 1\n",
    "\n",
    "with open('test.txt', 'r', encoding='utf-8') as f :\n",
    "\n",
    "    lineCountTest = 0\n",
    "\n",
    "    for line in f :\n",
    "\n",
    "        lineCountTest += 1\n",
    "\n",
    "print(lineCount)\n",
    "print(lineCountTrain)\n",
    "print(lineCountTest)\n",
    "print(lineCountTrain + lineCountTest)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizaremos el texto. La tokezinación será por oración que dijo el presidente, y cada oración estará tokenizada por palabra. Quitaremos los signos de puntuación, pero dejaremos los acentos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para quitar los signos de puntación y poner todo en minúsculas, además de poner el texto en una lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def noPuntuacion(text): return re.findall(r'[a-zA-ZñÑáéíóúÁÉÍÓÚüÜ]+', text.lower())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separaremos cada entrada del presidente en oraciones y creamos una lista de lista con cada oracion tokenizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# texto = []\n",
    "# sentence = str()\n",
    "\n",
    "# with open(\"conferencias_matutinas_amlo.txt\", \"r\", encoding='utf-8') as f:\n",
    "\n",
    "#     for i,line in enumerate(f) :\n",
    "\n",
    "#         for word in line :\n",
    "\n",
    "#             if word == '.' :\n",
    "\n",
    "#                 texto.append(noPuntuacion(sentence))\n",
    "#                 sentence = str()\n",
    "\n",
    "#             else :\n",
    "\n",
    "#                 sentence += word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def separacionCorpus(text, porcentage, seed) :\n",
    "\n",
    "#     rd.seed(seed)\n",
    "\n",
    "#     textTrain = text.copy()\n",
    "#     textTest = []\n",
    "#     testPart = int(len(textTrain)*porcentage/100)\n",
    "\n",
    "#     for i in range(testPart) :\n",
    "\n",
    "#         index = rd.randint(0,len(textTrain)-1) \n",
    "#         textTest.append(textTrain[index])\n",
    "#         del textTrain[index]\n",
    "\n",
    "#     return textTrain, textTest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libreta 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "textoPruebas = [[\"Ya\", \"nada\", \"más\", \"es\", \"como\", \"lo\", \"de\", \"Oaxaca\"],\n",
    "                [\"como\", \"lo\", \"de\", \"los\", \"caminos\", \"de\", \"Oaxaca\"], \n",
    "                [\"vamos\", \"a\", \"buscar\", \"el\", \"mecanismo\", \"entregarle\", \"los\", \"fondos\"],\n",
    "                [\"y\", \"que\", \"decidan\", \"democráticamente\", \"qué\", \"caminos\", \"construir\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que tenemos una lista de listas con todas las palabras tokenizadas, debemos de crear un n-grama de entrenamiento y el vocabulario.\n",
    "\n",
    "- Creamos el n-grama de entranamiento\n",
    "\n",
    "    - Primero acolchonamos las oraciones. Esto es poner uno o mas simbolos como inicio (\\<s>) y otro como fin (<\\s>) de oracion. Este acolchonamiento en la paqueteria de nltk es simetrico, esto es pone el mismo numero de simbolos al inicio como al final. La salida sera una lista de listas pero acolchonada\n",
    "    - Segundo convertir a un n-grama. Con la salida del paso anterior crearemos nuestro unigrama, bigrama, trigrama, etc. Para hacer el modelo mas robusto se pueden hacer n,(n-1),..,.1-gramas, esto es, si tenemos que el n-grama maximo que queremos es un trigrama, tambien podemos hacer bigramas y unigramas. La salida sera una lista de lista con el/los n-grama(s).\n",
    "\n",
    "- Creamos el vocabulario\n",
    "\n",
    "    - A la lista de listas acolchonada que hicimos en la creacion del n-grama simplemente la aplanamos, esto es, pasamos de una lista de listas a solo una lista donde tendremos todas las palabras de nuestro texto tokenizadas. La salida sera una lista acolchonada con las palabras tokenizadas.\n",
    "\n",
    "Para suerte de nosotros la paqueteria nltk ya tiene una funcion para realizar todo esto : \n",
    "\n",
    "**padded_everygram_pipeline(order, text)**\n",
    "\n",
    "Esta funcion recibe dos parametros, *order* y *text*. \n",
    "- Text es la lista de listas tokenizadas.\n",
    "- Order es el order del n-grama maximo, ya que esta funcion nos devuelve n,(n-1),..,.1-gramas. Ademas es el numero de acolchonamiento que tendran los n-gramas.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 1 : Unigramas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dicho lo anterior entonces para un Unigrama *order = 1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nModel1 = 1\n",
    "trainDataModel1, paddedVocabModel1 = padded_everygram_pipeline(nModel1, textoPruebas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para entrenar el modelo usaremos el estimador maximo de posibilidad, MLE por sus siglas en ingles (Maximum Likelihood Estimator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = MLE(nModel1) # Donde 1 dice el n-grama maximo "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto crea un vocabulario vacio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model1.vocab)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora llenamos el modelo. La longitud del vocabulario seria la cantidad de palabras sin repetir mas el token \\<UNK>, el cual es el token para identificar las palabras desconocidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Vocabulary with cutoff=1 unk_label='<UNK>' and 24 items>\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "model1.fit(trainDataModel1, paddedVocabModel1)\n",
    "print(model1.vocab)\n",
    "print(len(model1.vocab))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya con nuestro modelo entranado podremos ver cuales palabras de un texto estan en nuestro vocabulario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Ya', 'nada', 'más', 'es', 'como', 'lo', 'de', 'Oaxaca')\n",
      "('<UNK>', '<UNK>', '<UNK>', 'fondos')\n"
     ]
    }
   ],
   "source": [
    "print(model1.vocab.lookup(textoPruebas[0]))\n",
    "\n",
    "print(model1.vocab.lookup([\"serendipia\", \"snickers\", \"Universo\", \"fondos\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los modelos de n-gramas al final se reduce a contar los n-gramas del corpus de entranamiento. Para saber que tan probable son las palabras en un contexto particular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de veces que aparece el unigrama 'los' en el texto : 2\n",
      "Numero de veces que aparece el unigrama 'Oaxaca' en el texto : 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Numero de veces que aparece el unigrama 'los' en el texto : \" + str(model1.counts['los']))\n",
    "print(\"Numero de veces que aparece el unigrama 'Oaxaca' en el texto : \" + str(model1.counts['Oaxaca']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ademas de contar el numero de veces que aparece el unigrama podemos obtener la frecuencia relativa y el logaritmo de la frecuencia relativa, esta ultima es importante cuando tenemos un corpus muy grande ya que la frecuencia se vuelve demasiado pequenia y podemos caer en underflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frecuencia relativa de la palabra 'el' :0.03333333333333333\n",
      "Logaritmo de la frecuencia relativa de la palabra 'el' :-4.906890595608519\n",
      "Frecuencia relativa de una palabra fuera de vocabulario :0.0\n",
      "Logaritmo de la frecuencia relativa de una palabra fuera de vocabulario :-inf\n"
     ]
    }
   ],
   "source": [
    "print(\"Frecuencia relativa de la palabra 'el' :\" + str(model1.score('el')))\n",
    "print(\"Logaritmo de la frecuencia relativa de la palabra 'el' :\" + str(model1.logscore('el')))\n",
    "print(\"Frecuencia relativa de una palabra fuera de vocabulario :\" + str(model1.score('rl')))\n",
    "print(\"Logaritmo de la frecuencia relativa de una palabra fuera de vocabulario :\" + str(model1.logscore('rl')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como es un unigrama no podemos calcular la posibilidad de que una palabra prosiga a otra, como se ve en el siguiente ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(model1.score(\"los\", [\"fondos\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 2 : Bigramas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este modelo hacemos practicamente lo mismo que el modelo1, ahora el n-grama maximo sera 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Vocabulary with cutoff=1 unk_label='<UNK>' and 26 items>\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "nModel2 = 2\n",
    "trainDataModel2, paddedVocabModel2 = padded_everygram_pipeline(nModel2, textoPruebas)\n",
    "model2 = MLE(nModel2)\n",
    "model2.fit(trainDataModel2, paddedVocabModel2)\n",
    "print(model2.vocab)\n",
    "print(len(model2.vocab))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podremos buscar tanto unigramas como bigramas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de veces que aparece el unigrama 'los' en el texto : 2\n",
      "Numero de veces que aparece el unigrama 'Oaxaca' en el texto : 2\n",
      "Numero de veces que aparece el bigrama 'los fondos' en el texto : 1\n",
      "Numero de veces que aparece el bigrama 'de Oaxaca' en el texto : 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Numero de veces que aparece el unigrama 'los' en el texto : \" + str(model2.counts['los']))\n",
    "print(\"Numero de veces que aparece el unigrama 'Oaxaca' en el texto : \" + str(model2.counts['Oaxaca']))\n",
    "print(\"Numero de veces que aparece el bigrama 'los fondos' en el texto : \" + str(model2.counts[['los']]['fondos']))\n",
    "print(\"Numero de veces que aparece el bigrama 'de Oaxaca' en el texto : \" + str(model2.counts[['de']]['Oaxaca']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con bigramos ya podemos calcular la posibilidad de una palabra sea precedida de otra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posibilidad de 'los' de preceder de 'fondos' : 0.5\n",
      "Posibilidad de 'fondos' de preceder de 'los' : 0.0\n",
      "Logaritmo de la posibilidad de 'los' de preceder de 'fondos' : -1.0\n",
      "Logaritmo de la posibilidad de 'fondos' de preceder de 'los' : -inf\n"
     ]
    }
   ],
   "source": [
    "print(\"Posibilidad de 'los' de preceder de 'fondos' : \" + str(model2.score(\"fondos\", [\"los\"])))\n",
    "print(\"Posibilidad de 'fondos' de preceder de 'los' : \" + str(model2.score(\"los\", [\"fondos\"])))\n",
    "print(\"Logaritmo de la posibilidad de 'los' de preceder de 'fondos' : \" + str(model2.logscore(\"fondos\", [\"los\"])))\n",
    "print(\"Logaritmo de la posibilidad de 'fondos' de preceder de 'los' : \" + str(model2.logscore(\"los\", [\"fondos\"])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que tenemos nuestro modelo entrenado con un corpus especifico que pasara al enfrentarlo con situaciones reales?. Nuestro corpus no tiene todas las palabras y suponiendo que si las tiene, el lenguaje evoluciona creando nuevas palabras, entonces cuando nuestro modelo de lenguaje se encuentre con estas nuevas palabras al estimar su posibilidad de preceder o de seguir en una oracion obtendremos cero, lo cual es muy problematico ya que la posibilidad de una oracion se calcula como el producto de las posibilidades de cada palabras en ella.\n",
    "\n",
    "En el modelo 1 y 2 usamos el estimador de maxima posibilidad, que esta dado por la siguiente ecuacion :\n",
    "\n",
    "$\n",
    "P(w_n | w_{n-N+1}^{n-1}) = \\frac{C(w_{n-N+1}^{n-1}W_n)}{C(w_{n-N+1}^{n-1})} \n",
    "$\n",
    "\n",
    "Donde N es el tipo de N-grama; $N=2$ es un bigrama, $w_1^n$ es la secuencia de palabras; $w_1^n = w_1w_2 \\cdots w_n$, C(s) es la frecuencia que aparece la oracion s en el corpus de entrenamiento. \n",
    "\n",
    "Entonces para evitar obtener $P(w|s) = 0$ cuando $w$ es una palabra nueva usamos una tecnica de suavizado. Existe varias de estas tecnicas, por ejemplo :\n",
    "\n",
    "1. Suavizado de Laplace\n",
    "2. suavizado de Good-Turing\n",
    "3. Interpolacion simple de Jelinek-Mercer \n",
    "4. Discontinuidad absoluta\n",
    "5. Suavizado de Kneser-Ney\n",
    "6. Suavizado de Katz\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 3 : Suavizado de Laplace"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El suavizado de Laplace basicamente solo aniade un 1 a todas frecuencias de aparicion de una oracion para eliminar los 0's. Cambiando el calculo de la posibilidad a la siguiente ecuacion :\n",
    "\n",
    "$\n",
    "P(w_n | w_{n-N+1}^{n-1}) = \\frac{C(w_{n-N+1}^{n-1}W_n) + 1}{C(w_{n-N+1}^{n-1}) + V} \n",
    "$\n",
    "\n",
    "Donde V es el tamanio del vocabulario."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comparar con el modelo MLE usaremos el mismo tratamiento para obtener los datos de entrenamiento y vocabulario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Vocabulary with cutoff=1 unk_label='<UNK>' and 26 items>\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "nModel3 = 2\n",
    "trainDataModel3, paddedVocabModel3 = padded_everygram_pipeline(nModel3, textoPruebas)\n",
    "model3 = Laplace(nModel3)\n",
    "model3.fit(trainDataModel3, paddedVocabModel3)\n",
    "print(model3.vocab)\n",
    "print(len(model3.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(los fondos) usando MLE : 0.5\n",
      "P(los fondos) usando Laplace : 0.07142857142857142\n",
      "P(fondos los) usando MLE : 0.0\n",
      "P(fondos los) usando Laplace : 0.037037037037037035\n"
     ]
    }
   ],
   "source": [
    "print(\"P(los fondos) usando MLE : \" + str(model2.score(\"fondos\", [\"los\"])))\n",
    "print(\"P(los fondos) usando Laplace : \" + str(model3.score(\"fondos\", [\"los\"])))\n",
    "print(\"P(fondos los) usando MLE : \" + str(model2.score(\"los\", [\"fondos\"])))\n",
    "print(\"P(fondos los) usando Laplace : \" + str(model3.score(\"los\", [\"fondos\"])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donde vemos como la posibilidad se hace diferente de cero con el suavizado de Laplace."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 4 : Escoger un suavizado de la libreria"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escogeremos el suavizado de Kneser-Ney. De igual manera el vocabulario y datos de entrenamiento se obtendran como en los modelos anteriores para poderlos comparar.\n",
    "\n",
    "Esta suavizado esta dado por la siguiente ecuacion :\n",
    "\n",
    "\n",
    "$P(w_i | w_{i-1}) = \n",
    "    \\left\\lbrace\\begin{array}{c} \n",
    "        \\frac{max \\{C(w_{i-1}w_i) - D,0\\}}{C(w_{i-1})} \\hspace{0.5cm} \\text{si} \\hspace{0.5cm} C(w_{i-1}w_i) > 0  \\\\\n",
    "        \\alpha(w_{i-1})P(w_i) \\hspace{0.5cm} \\text{si} \\hspace{0.5cm} \\text{de otra manera}\n",
    "    \\end{array}\\right.\n",
    "$\n",
    "\n",
    "Con\n",
    "\n",
    "$\n",
    "P(w_i) = \\frac{C(\\bullet w_i)}{\\sum_{ w_i}C(\\bullet w_i)}\n",
    "$\n",
    "\n",
    "Y $C(\\bullet w_i)$ es el numero de palabras unicas que preceden $w_i$. Por otro lado $\\alpha(w_{i-1})$ es elegido para hacer la suma de la distribucion igual a 1 :\n",
    "\n",
    "$\n",
    "\\alpha(w_{i-1}) = \\frac{1 - \\sum_{w_i:C(w_{i_1}w_i)>0}\\frac{max\\{C(w_{i-1}w_i) - D,0\\}}{C(w_{i-1})}}{1 - \\sum_{w_i:C(w_{i_1}w_i)>0}P(w_i)}\n",
    "$\n",
    "\n",
    "En la ecuacion del suavizado tenemos $D$ que es un parametro que le da a la funcion, este se llama descuento y toma valores en el intervalo $[0,1]$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Vocabulary with cutoff=1 unk_label='<UNK>' and 26 items>\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "nModel4 = 2\n",
    "D = 0.0\n",
    "trainDataModel4, paddedVocabModel4 = padded_everygram_pipeline(nModel4, textoPruebas)\n",
    "model4 = KneserNeyInterpolated(nModel4, D)\n",
    "model4.fit(trainDataModel4, paddedVocabModel4)\n",
    "print(model4.vocab)\n",
    "print(len(model4.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(los fondos) usando MLE : 0.5\n",
      "P(los fondos) usando Laplace : 0.07142857142857142\n",
      "P(los fondos) usando Kneser-Ney : 0.5\n",
      "P(fondos los) usando MLE : 0.0\n",
      "P(fondos los) usando Laplace : 0.037037037037037035\n",
      "P(fondos los) usando Kneser-Ney : 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"P(los fondos) usando MLE : \" + str(model2.score(\"fondos\", [\"los\"])))\n",
    "print(\"P(los fondos) usando Laplace : \" + str(model3.score(\"fondos\", [\"los\"])))\n",
    "print(\"P(los fondos) usando Kneser-Ney : \" + str(model4.score(\"fondos\", [\"los\"])))\n",
    "print(\"P(fondos los) usando MLE : \" + str(model2.score(\"los\", [\"fondos\"])))\n",
    "print(\"P(fondos los) usando Laplace : \" + str(model3.score(\"los\", [\"fondos\"])))\n",
    "print(\"P(fondos los) usando Kneser-Ney : \" + str(model4.score(\"los\", [\"fondos\"])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De igual manera que con el suavizado de Laplace, eliminamos la posibilidad cero. Pero jugando con el valor de $D$ descubrimos que si $D=0$ nos vuelven los mismos resultados que con el modelo MLE. Ademas entre mas disminuya $D$ la posibilidad de una oracion que si estaba en el corpus de entrenamiento aumenta."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluacion intrinseca de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generacion de texto"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "ca4ae65869d2cb0a1ce9a252154e55d284ddfed7dca74e9ec9cf70dfaaed74d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
